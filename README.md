# jsScraper

> ğŸ” A comprehensive, Python-based JavaScript scraping and archiving tool built on Playwright. Designed for security researchers, bug bounty hunters, developers, and analysts to extract, filter, and save JavaScript files (external & inline) from any target website.

---

## ğŸš€ Overview

**jsScraper** allows you to scan web pages for JavaScript files â€” both external and inline â€” and archive them with options to:

- Filter out common libraries and tracking scripts
- Deduplicate using SHA-256 hashes
- Crawl internal pages
- Collect cross-origin resources (optional)
- Generate verbose output logs
- Process entire URL lists

Its powerful combination of **asynchronous scraping**, **Playwright automation**, and **smart filtering** makes it suitable for recon, compliance, forensics, and competitive intelligence.

---

## âš™ï¸ Features

| Feature                  | Description                                                                 |
|--------------------------|-----------------------------------------------------------------------------|
| ğŸ“‚ External JS Collection | Captures all loaded `.js` files on target page                              |
| ğŸ§  Inline Script Parsing  | Extracts `<script>` blocks from HTML content                                |
| âœ‚ï¸ Filtering Engine       | Removes tracking scripts, analytics, and known libraries using regex        |
| ğŸ”„ Deduplication          | Saves only unique scripts based on SHA-256 hash                             |
| ğŸŒ Crawling               | Optional crawling of internal links up to specified depth                   |
| ğŸ Cross-Origin Capture   | Capture JS from third-party domains if required                             |
| ğŸªµ Logging                | Verbose log file (`verbose.log`) and clean CLI logging                      |
| ğŸ§ª Batch Mode             | Accepts a list of target URLs from file                                     |
| ğŸ” Privacy-Aware          | Skips sensitive patterns & analytics tools (e.g., GA, Segment, Hotjar)      |

---

## ğŸ§° Requirements

- Python 3.8+
- Dependencies:
  - `playwright`
  - `validators`
  - `beautifulsoup4`

### Installation

```bash
pip install -r requirements.txt
playwright install
```

---

## ğŸ§ª Usage Examples

### ğŸ“„ Basic Usage

```bash
python jsScraper.py https://example.com
```

### ğŸ” From URL File

```bash
python jsScraper.py --url-file urls.txt
```

### âš™ï¸ Full Options

```bash
python jsScraper.py https://example.com \
  --output output_dir \
  --filter strict \
  --min-size 200 \
  --crawl \
  --max-depth 2 \
  --cross-origin \
  --clear \
  --verbose
```

---

## ğŸ§¾ CLI Arguments

| Argument         | Description                                                           |
| ---------------- | --------------------------------------------------------------------- |
| `url`            | Target website to scrape (e.g., [https://site.com](https://site.com)) |
| `--url-file`     | Path to file with list of URLs (overrides `url`)                      |
| `-o, --output`   | Output directory (default: `getJsOutput`)                             |
| `--filter`       | Filtering mode: `strict` (default) or `relaxed`                       |
| `--min-size`     | Minimum file size in bytes (default: 150)                             |
| `--crawl`        | Enable crawling of internal links                                     |
| `--max-depth`    | Max depth for crawling (default: 2)                                   |
| `--cross-origin` | Include third-party JS                                                |
| `--clear`        | Clear output folder before writing new data                           |
| `-t, --timeout`  | Page timeout in seconds (default: 60)                                 |
| `-r, --delay`    | Delay between downloads in seconds (default: 0.5)                     |
| `-v, --verbose`  | Enable verbose logging (saved to `verbose.log`)                       |

---

## ğŸ“ Output Structure

Files are saved as:

```
<output_dir>/<domain>/<filter_mode>/
  â”œâ”€â”€ 001_example_com_main_f3ab23d4.js
  â”œâ”€â”€ 002_example_com_inline_1a2b3c4d.js
  â”œâ”€â”€ ...
  â””â”€â”€ verbose.log
```

Each JS file is uniquely named using:

* Index
* Domain
* Path
* Content hash (SHA-256, first 8 chars)

---

## ğŸ§  Use Cases

### ğŸ” Security Research

* Extract inline secrets, endpoints, or tokens
* Identify outdated/vulnerable JS libraries
* Use in bug bounty / recon workflows


### ğŸ§¾ Web Archiving / Forensics

* Archive all JS on a domain for future analysis
* Identify scripts used in past attacks or shady behavior

---

## ğŸ“‹ Filtering Modes

* **strict**: Blocks most common analytics, CDNs, libraries
* **relaxed**: Allows more JS through (themes, plugins, etc)

Custom patterns can be added to `UNINTERESTING_JS_STRICT` and `UNINTERESTING_JS_RELAXED` in the script.

---

## ğŸ“¦ requirements.txt

```txt
playwright
validators
beautifulsoup4
```

---

## ğŸ›¡ License

**MIT License** â€” Free to use, modify, and redistribute. See `LICENSE` for details.

---

## ğŸ¤ Contributing

Pull requests and feature requests are welcome!

Ideas:

* Plugin engine (e.g., secrets detection)
* JS beautification/deobfuscation
* JSON summary report
* Docker wrapper

---

## ğŸ‘¨â€ğŸ’» Author

Developed by **[249BUG](https://github.com/exe249)** â€” built for recon professionals, security analysts, and digital investigators.
